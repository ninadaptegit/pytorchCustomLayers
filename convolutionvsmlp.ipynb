{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOr3SUc5fwIC7sX/5cgOHTf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ninadaptegit/pytorchCustomLayers/blob/main/convolutionvsmlp.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lMCbItfbSQQ6"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.datasets import fetch_openml\n",
        "\n",
        "import pandas as pd\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Fetching and Preprocessing"
      ],
      "metadata": {
        "id": "noV4YicZXCfZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mnist = fetch_openml('mnist_784', version=1, as_frame=False)\n",
        "X, y = mnist.data[:5000,:], mnist.target[:5000]\n"
      ],
      "metadata": {
        "id": "pilZ2dXCUF2w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape,y.shape"
      ],
      "metadata": {
        "id": "6uwTYbjFGgp2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ],
      "metadata": {
        "id": "najXh2KBOmbC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,shuffle = True,random_state=42)"
      ],
      "metadata": {
        "id": "xErop9-hUH2r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
      ],
      "metadata": {
        "id": "Wjz6MxXqUT4a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "y_train = y_train.astype(int).reshape(y_train.shape[0],-1)\n",
        "y_test = y_test.astype(int).reshape(y_test.shape[0],-1)\n",
        "\n",
        "onehot = OneHotEncoder(sparse_output=False)\n",
        "y_train = onehot.fit_transform(y_train)\n",
        "y_test = onehot.fit_transform(y_test)"
      ],
      "metadata": {
        "id": "Ne078WMgVgsQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = torch.tensor(X_train)\n",
        "X_test = torch.tensor(X_test)\n",
        "y_train = torch.tensor(y_train)\n",
        "y_test = torch.tensor(y_test)"
      ],
      "metadata": {
        "id": "wkqh5RmFUsjh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# y_train = torch.unsqueeze(y_train,dim=1)\n",
        "# y_test = torch.unsqueeze(y_test,dim=1)"
      ],
      "metadata": {
        "id": "5YLNeXDcVDBX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = X_train.to(device)\n",
        "X_test = X_test.to(device)\n",
        "y_train = y_train.to(device)\n",
        "y_test = y_test.to(device)"
      ],
      "metadata": {
        "id": "Ee5wUyudVNKT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = X_train.type(torch.float)\n",
        "X_test = X_test.type(torch.float)\n",
        "y_train = y_train.type(torch.float)\n",
        "y_test = y_test.type(torch.float)"
      ],
      "metadata": {
        "id": "PUJTTBYoWa41"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mean = X_train.mean()\n",
        "std = X_train.std()"
      ],
      "metadata": {
        "id": "8bAMAr3bWnRf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mean , std"
      ],
      "metadata": {
        "id": "AM-nY6h5W3Ph"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = (X_train - mean)/std\n",
        "X_test = (X_test - mean)/std"
      ],
      "metadata": {
        "id": "Auu-w109W3Mg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pandas = pd.DataFrame(y)"
      ],
      "metadata": {
        "id": "jt_mM1FkW3KT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spread = y_pandas.value_counts().sort_index()\n",
        "plt.figure(figsize=(8, 4))\n",
        "spread.plot(kind='bar', color='skyblue', edgecolor='black')\n",
        "\n",
        "plt.title(\"MNIST Label Distribution\")\n",
        "plt.xlabel(\"Digit Label\")\n",
        "plt.ylabel(\"Frequency\")\n",
        "plt.xticks(rotation=0)\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "zPv5qBolW3Il"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomFullyConnectedLayer(nn.Module):\n",
        "  def __init__(self, input_size, output_size,  activation = None):\n",
        "    super().__init__()\n",
        "    self.weights = nn.Parameter(torch.randn(output_size, input_size))\n",
        "    self.bias = nn.Parameter(torch.randn(output_size,))\n",
        "    self.activation = activation\n",
        "  def forward(self, x):\n",
        "\n",
        "    # x = (batch_size , in_nodes) After straightning the input\n",
        "    # print(x.shape, self.weights.shape,self.bias.shape)\n",
        "    z =  torch.matmul(x,self.weights.T) + self.bias\n",
        "    if self.activation is not None:\n",
        "\n",
        "      # To support custom activation functions example given below\n",
        "      if isinstance(self.activation, type) and issubclass(self.activation, torch.autograd.Function):\n",
        "        z = self.activation.apply(z)\n",
        "      else:\n",
        "        z = self.activation(z)\n",
        "    return z\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "JD6fr5XNG9UG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomActivationFunction(torch.autograd.Function):\n",
        "    @staticmethod\n",
        "    def forward(ctx, input):\n",
        "        ctx.save_for_backward(input)\n",
        "        return input**2  # x^2\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx, grad_output):\n",
        "        input, = ctx.saved_tensors\n",
        "        grad_input = 2 * input * grad_output\n",
        "        return grad_input"
      ],
      "metadata": {
        "id": "kreZ-zjmMu2S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomPooling2D(nn.Module):\n",
        "  def __init__(self, kernel_size , stride = 1 , padding = 0 , mode = 'max'):\n",
        "    super().__init__()\n",
        "\n",
        "    self.kernel_size = (kernel_size,kernel_size)\n",
        "    self.stride = stride\n",
        "    self.padding = padding\n",
        "    self.mode = mode\n",
        "\n",
        "  def forward(self, x):\n",
        "    B,C,H,W = x.shape\n",
        "    kH,kW = self.kernel_size\n",
        "    x = torch.nn.functional.pad(x,(self.padding,self.padding,self.padding,self.padding))\n",
        "    patches = torch.nn.functional.unfold(x,kernel_size= self.kernel_size, stride = self.stride)\n",
        "    patches = patches.view(B,C,kH*kW,-1)\n",
        "    if self.mode == 'max':\n",
        "      pooled = patches.max(dim=2).values\n",
        "    else:\n",
        "      pooled = patches.mean(dim=2)\n",
        "\n",
        "    H_out = (H + 2 * self.padding - kH) // self.stride + 1\n",
        "    W_out = (W + 2 * self.padding - kW) // self.stride + 1\n",
        "\n",
        "    return pooled.view(B, C, H_out, W_out)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "vpbtNNcxT8X1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomFlattenLayer(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "\n",
        "  def forward(self , x):\n",
        "    return x.view(x.shape[0],-1)"
      ],
      "metadata": {
        "id": "z69Q11H_xnw8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomConv2D(nn.Module):\n",
        "  def __init__(self,  in_channels , out_channels , kernel_size , stride = 1  , padding = 0 , activation = None):\n",
        "    super().__init__()\n",
        "    self.stride = stride\n",
        "    self.padding = padding\n",
        "    self.kH , self.kW = kernel_size\n",
        "    self.out_channels = out_channels\n",
        "    self.activation = activation\n",
        "    self.weight = nn.Parameter(torch.randn(out_channels,in_channels,self.kH,self.kW))\n",
        "    self.bias = nn.Parameter(torch.randn(out_channels))\n",
        "\n",
        "\n",
        "  def forward(self , x):\n",
        "    # B is Batch_size , C_in is input channels, H, W\n",
        "    Batch_size,C_in,H,W = x.shape\n",
        "    # print(f\"Batch size = {Batch_size} Input channels = {C_in} Height = {H} Width = {W}\")\n",
        "\n",
        "    # Add some padding to the input matrix based on what padding was given in the\n",
        "    # constructor\n",
        "    x = torch.nn.functional.pad(x , (self.padding,self.padding,self.padding , self.padding))\n",
        "\n",
        "    # Get the kernal patches where kernal should be multiplied at using unfold\n",
        "    # Look at the patches vertically, each column corresponds to to the kernal multiplied over the in_dim after the weight matrix is flattened.\n",
        "    patches = torch.nn.functional.unfold(x,kernel_size = (self.kH,self.kW),stride = self.stride)\n",
        "\n",
        "    # Flatten the weight matrix to help with the matrix multiplication operation\n",
        "    # The first dim corresponds to the out_dim. So I am multiplying each row of the weight matrix to the column of the patch matrix. each row multiplication corresponds to\n",
        "    # corresponds to each output matrix.\n",
        "    W_flat = self.weight.view(self.weight.shape[0] , -1)\n",
        "    # print(W_flat.shape,patches.shape)\n",
        "    # Multiply the Weight and the patches\n",
        "    out = W_flat.matmul(patches)\n",
        "\n",
        "    # Add the bias term to each of the output matrices\n",
        "    out = out + self.bias[:,None]\n",
        "\n",
        "    # make sure the dimensions of the output align with (Batch , output_size, number of patches)\n",
        "    out = out.permute(1,0,2)\n",
        "\n",
        "    H_out = (H + 2*self.padding - self.kH)//self.stride + 1\n",
        "    W_out = (W + 2*self.padding - self.kW)//self.stride + 1\n",
        "\n",
        "    # print(f\"Out Channels = {self.out_channels} H_out = {H_out} W_out = {W_out} Batch Size = {Batch_size}\")\n",
        "\n",
        "    # reshape in memory to match the size of the output result with formula\n",
        "    # H_new = (H_old - kernal_size + 2*P)//stride + 1\n",
        "\n",
        "    out = out.reshape(Batch_size,self.out_channels,H_out,W_out)\n",
        "    if self.activation is not None:\n",
        "      if isinstance(self.activation, type) and hasattr(self.activation, 'apply'):\n",
        "          out = self.activation.apply(out)\n",
        "      else:\n",
        "          out = self.activation(out)\n",
        "    return out\n",
        "\n"
      ],
      "metadata": {
        "id": "IZfrMO2_0TK4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "metadata": {
        "id": "f2PxUN9Izgux"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ConvModel(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    # 28*28\n",
        "    self.conv2d_fir = CustomConv2D(in_channels = 1, out_channels = 8, kernel_size = (3,3), stride = 1, padding=2,activation = nn.ReLU())\n",
        "    # 30*30\n",
        "    self.maxpool_fir = CustomPooling2D(kernel_size = 2, stride = 2, mode = 'max')\n",
        "    # 15*15\n",
        "    self.conv2d_sec = CustomConv2D(in_channels = 8, out_channels = 16, kernel_size = (5,5), stride = 1, padding=2,activation = nn.ReLU())\n",
        "    # 15*15\n",
        "    self.maxpool_sec = CustomPooling2D(kernel_size = 2, stride = 2, mode = 'max')\n",
        "    # 16*7*7\n",
        "    self.flatten = CustomFlattenLayer()\n",
        "    #\n",
        "    self.fully_con = CustomFullyConnectedLayer(input_size = 784 , output_size = 10 )\n",
        "  def forward(self, x):\n",
        "\n",
        "    x = self.conv2d_fir(x)\n",
        "    # print(f\"Shape of output from first conv2d is {x.shape}\")\n",
        "    x = self.maxpool_fir(x)\n",
        "    # print(f\"Shape of output from first pool is {x.shape}\")\n",
        "    x = self.conv2d_sec(x)\n",
        "    # print(f\"Shape of output from second conv2d is {x.shape}\")\n",
        "    x = self.maxpool_sec(x)\n",
        "    # print(f\"Shape of output from second pool is {x.shape}\")\n",
        "    flat = self.flatten(x)\n",
        "    # print(f\"Shape of output from flatten is {flat.shape}\")\n",
        "    ans = self.fully_con(flat)\n",
        "    return ans\n"
      ],
      "metadata": {
        "id": "LHNrRiW89om0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "e0aOjU2rBJtM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "convModel = ConvModel().to(device)"
      ],
      "metadata": {
        "id": "B_9pSc_iA-uS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test_hold = X_test.reshape(X_test.shape[0],28,28)\n",
        "X_test_hold = X_test_hold.unsqueeze(dim=0)\n",
        "X_test_hold = X_test_hold.permute(1,0,2,3)\n",
        "X_train_hold = X_train.reshape(X_train.shape[0],28,28)\n",
        "X_train_hold = X_train_hold.unsqueeze(dim=0)\n",
        "X_train_hold = X_train_hold.permute(1,0,2,3)\n"
      ],
      "metadata": {
        "id": "_C8lJLN_Iyp5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epoch_ls = []\n",
        "test_ls_conv = [[],[]]\n",
        "train_ls_conv = [[],[]]\n"
      ],
      "metadata": {
        "id": "SxC96ip7Tkno"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conv_num = 0"
      ],
      "metadata": {
        "id": "Q2PiRdXRYGKU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm.notebook import tqdm\n",
        "epochs = 5000\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(convModel.parameters(), lr=0.01,weight_decay=1e-5)\n",
        "\n",
        "for epoch in tqdm(range(epochs)):\n",
        "  convModel.train()\n",
        "  y_pred = convModel(X_train_hold)\n",
        "  loss = loss_fn(y_pred,y_train)\n",
        "  optimizer.zero_grad()\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "  convModel.eval()\n",
        "  with torch.inference_mode():\n",
        "    y_test_pred = convModel(X_test_hold)\n",
        "    loss_test = loss_fn(y_test_pred,y_test)\n",
        "\n",
        "  if epoch%10 == 0:\n",
        "    print(f\"Epoch = {epoch} Loss = {loss}\")\n",
        "    print(f\"Test Loss = {loss_test}\")\n",
        "    epoch_ls.append(epoch)\n",
        "    test_ls_conv[conv_num].append(loss_test)\n",
        "    train_ls_conv[conv_num].append(loss)\n",
        "\n"
      ],
      "metadata": {
        "id": "aUnD_TERBGg5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ls_num = [[],[]]\n",
        "test_ls_num = [[],[]]\n",
        "train_ls_num[0] = [x.item() for x in train_ls_conv[0]]\n",
        "test_ls_num[0] = [x.item() for x in test_ls_conv[0]]\n",
        "train_ls_num[1] = [x.item() for x in train_ls_conv[1]]\n",
        "test_ls_num[1] = [x.item() for x in test_ls_conv[1]]"
      ],
      "metadata": {
        "id": "5ek_W3DRHAMT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_ls_conv[1])"
      ],
      "metadata": {
        "id": "N_6ygfm-yPUX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "plt.figure(figsize=(10,6))\n",
        "plt.plot(epoch_ls,train_ls_num[1],label = \"Train Loss Model CNN : 1\",c='lightgreen')\n",
        "plt.plot(epoch_ls,test_ls_num[1],label = \"Test Loss Model CNN : 1\",c='lightcoral')\n",
        "\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "R_bMVMsKJ3NZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "h8DAJVMCRT8w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_ywnv4QFRYdh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# with open(\"loss_data_CN.py\", \"w\") as f:\n",
        "#     f.write(f\"train_losses = {train_ls_num}\\n\")\n",
        "#     f.write(f\"test_losses = {test_ls_num}\\n\")"
      ],
      "metadata": {
        "id": "H48Jp52wcyCP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fully Connected layer"
      ],
      "metadata": {
        "id": "XkUsuW8GiKnj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class FullyConnected(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.fcl1 = CustomFullyConnectedLayer(input_size = 784 , output_size = 16 , activation = nn.ReLU())\n",
        "    self.fcl2 = CustomFullyConnectedLayer(input_size = 16 , output_size = 10 , activation = None)\n",
        "\n",
        "  def forward(self,  x):\n",
        "    x = x.view(x.shape[0],-1)\n",
        "    x = self.fcl1(x)\n",
        "    x = self.fcl2(x)\n",
        "    return x\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "B0f7W1LARo9K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_full = FullyConnected().to(device)"
      ],
      "metadata": {
        "id": "hwR9pUcdVFuc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epoch_ls = []\n",
        "test_ls_full = [[],[]]\n",
        "train_ls_full = [[],[]]"
      ],
      "metadata": {
        "id": "hdzGbGIUh-HY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conv_num = 1"
      ],
      "metadata": {
        "id": "LcO8GdYLVq45"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm.notebook import tqdm\n",
        "epochs = 5000\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model_full.parameters(), lr=0.001)\n",
        "\n",
        "for epoch in tqdm(range(epochs)):\n",
        "  model_full.train()\n",
        "  y_pred = model_full(X_train_hold)\n",
        "  loss = loss_fn(y_pred,y_train)\n",
        "  optimizer.zero_grad()\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "  model_full.eval()\n",
        "  with torch.inference_mode():\n",
        "    y_test_pred = model_full(X_test_hold)\n",
        "    loss_test = loss_fn(y_test_pred,y_test)\n",
        "\n",
        "  if epoch%10 == 0:\n",
        "    print(f\"Epoch = {epoch} Loss = {loss}\")\n",
        "    print(f\"Test Loss = {loss_test}\")\n",
        "    # epoch_ls.append(epoch)\n",
        "    test_ls_full[conv_num].append(loss_test)\n",
        "    train_ls_full[conv_num].append(loss)\n",
        "\n"
      ],
      "metadata": {
        "id": "47Z_tyYqV3Oz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_ls_full1 = [[],[]]\n",
        "train_ls_full1 = [[],[]]\n",
        "train_ls_full1[0] = [x.item() for x in train_ls_full[0]]\n",
        "test_ls_full1[0] = [x.item() for x in test_ls_full[0]]\n",
        "train_ls_full1[1] = [x.item() for x in train_ls_full[1]]\n",
        "test_ls_full1[1] = [x.item() for x in test_ls_full[1]]"
      ],
      "metadata": {
        "id": "a9qFUwhYkj24"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epoch_ls = [x for x in range(0,5000,10)]"
      ],
      "metadata": {
        "id": "leI1_aVQyto_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "plt.figure(figsize=(10,6))\n",
        "# plt.plot(epoch_ls,train_ls_full1[0],label = \"Train Loss Model MLP : 1\",c='lightgreen')\n",
        "# plt.plot(epoch_ls,test_ls_full1[0],label = \"Test Loss Model MLP : 1\",c='lightcoral')\n",
        "plt.ylim([0,10])\n",
        "plt.plot(epoch_ls,train_ls_full1[1],label = \"Train Loss Model MLP : 2\",c='darkgreen')\n",
        "plt.plot(epoch_ls,test_ls_full1[1],label = \"Test Loss Model MLP : 2\",c='red')\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Yx3eJuOKW3r8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_ls_full[1])"
      ],
      "metadata": {
        "collapsed": true,
        "id": "LfaLnobnkN3_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10,6))\n",
        "# plt.plot(epoch_ls,test_ls_num[0],label = \"Test Loss Model CNN : 1\",c='green')\n",
        "plt.plot(epoch_ls,test_ls_num[1],label = \"Test Loss Model CNN : 2\",c='lightgreen')\n",
        "# plt.plot(epoch_ls,test_ls_full1[0],label = \"Test Loss Model MLP : 1\",c='lightcoral')\n",
        "plt.ylim([0,10])\n",
        "plt.plot(epoch_ls,test_ls_full1[1],label = \"Test Loss Model MLP : 2\",c='red')\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "A6B_i1YWkOda"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
      ],
      "metadata": {
        "id": "N5NqzPdWmFLw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "count_parameters(model_full)"
      ],
      "metadata": {
        "id": "jszn5rL-miE0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "count_parameters(convModel)"
      ],
      "metadata": {
        "id": "rPYDiJA6mv-Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_cnn = convModel(X_test_hold)\n",
        "y_pred_full = model_full(X_test_hold)\n"
      ],
      "metadata": {
        "id": "it-hjsYamxwF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_cnn = torch.argmax(y_pred_cnn,dim=1)\n",
        "y_pred_full = torch.argmax(y_pred_full,dim=1)\n",
        "y_test_hold = torch.argmax(y_test,dim=1)"
      ],
      "metadata": {
        "id": "RYJE9ZoEoP_k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_cnn = y_pred_cnn.detach().cpu()\n",
        "y_pred_full = y_pred_full.detach().cpu()\n",
        "y_test_hold = y_test_hold.detach().cpu()"
      ],
      "metadata": {
        "id": "lHnrhzg_oXXB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "accuracy_score(y_pred_cnn,y_test_hold)"
      ],
      "metadata": {
        "id": "9wkrRcUdolUI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TKc1e1h6oo7s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BGNgL7PYo4F_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}